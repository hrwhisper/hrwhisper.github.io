<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/site/avatar.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/site/avatar.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/site/avatar.jpg">
  <link rel="mask-icon" href="/images/site/avatar.jpg" color="#222">
  <meta name="google-site-verification" content="fMKqXfnCsLFKKj0NjoZZApB_BuqLVUiJxtRkj-rznU4">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.hrwhisper.me","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="FM和FMM模型在数据量比较大并且特征稀疏的情况下，仍然有优秀的性能表现，在CTR&#x2F;CVR任务上尤其突出。 近些年来，深度学习的方法也开始应用在广告计算领域，因此本文也会对FM和FFM的深度学习版本做一个介绍。 本文包括：  FM 模型 FFM 模型 Deep FM 模型 Deep FFM模型">
<meta property="og:type" content="article">
<meta property="og:title" content="『我爱机器学习』FM、FFM与DeepFM">
<meta property="og:url" content="https://www.hrwhisper.me/machine-learning-fm-ffm-deepfm-deepffm/index.html">
<meta property="og:site_name" content="细语呢喃">
<meta property="og:description" content="FM和FMM模型在数据量比较大并且特征稀疏的情况下，仍然有优秀的性能表现，在CTR&#x2F;CVR任务上尤其突出。 近些年来，深度学习的方法也开始应用在广告计算领域，因此本文也会对FM和FFM的深度学习版本做一个介绍。 本文包括：  FM 模型 FFM 模型 Deep FM 模型 Deep FFM模型">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/fm-feaure-pair.png">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/fm-matrix-factorization.png">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/poly2-model-example.png">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/fm-model-example.png">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/ffm-model-example.png">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/ffm-model-training.png">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/deep-fm-part.png">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/deep-embedding.png">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/deep-fm.png">
<meta property="og:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/deep-ffm.jpg">
<meta property="article:published_time" content="2018-06-15T03:48:57.000Z">
<meta property="article:modified_time" content="2020-10-29T15:34:30.624Z">
<meta property="article:author" content="hrwhisper">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Machine Learning model">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.hrwhisper.me/images/machine-learning-fm-ffm-deepfm-deepffm/fm-feaure-pair.png">

<link rel="canonical" href="https://www.hrwhisper.me/machine-learning-fm-ffm-deepfm-deepffm/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>『我爱机器学习』FM、FFM与DeepFM | 细语呢喃</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-69270533-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-69270533-1');
      }
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d6a8cb42bd9ae728375b6726daa75e95";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">细语呢喃</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">技术改变生活</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">26</span></a>

  </li>
        <li class="menu-item menu-item-leetcode">

    <a href="/leetcode-algorithm-solution/" rel="section"><i class="fa fa-archive fa-fw"></i>leetcode</a>

  </li>
        <li class="menu-item menu-item-friends">

    <a href="/friend-link/" rel="section"><i class="fa fa-link fa-fw"></i>friends</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about-me/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.hrwhisper.me/machine-learning-fm-ffm-deepfm-deepffm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/site/avatar.jpg">
      <meta itemprop="name" content="hrwhisper">
      <meta itemprop="description" content="一个分享机器学习、算法与数据结构，个人学习心得、读书笔记、生活的博客。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="细语呢喃">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          『我爱机器学习』FM、FFM与DeepFM
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-15 11:48:57" itemprop="dateCreated datePublished" datetime="2018-06-15T11:48:57+08:00">2018-06-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/study/" itemprop="url" rel="index"><span itemprop="name">study</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/study/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          
            <span id="/machine-learning-fm-ffm-deepfm-deepffm/" class="post-meta-item leancloud_visitors" data-flag-title="『我爱机器学习』FM、FFM与DeepFM" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">评论数：</span>
    
    <a title="valine" href="/machine-learning-fm-ffm-deepfm-deepffm/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/machine-learning-fm-ffm-deepfm-deepffm/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>FM和FMM模型在数据量比较大并且特征稀疏的情况下，仍然有优秀的性能表现，在CTR/CVR任务上尤其突出。</p>
<p>近些年来，深度学习的方法也开始应用在广告计算领域，因此本文也会对FM和FFM的深度学习版本做一个介绍。</p>
<p>本文包括：</p>
<ul>
<li>FM 模型</li>
<li>FFM 模型</li>
<li>Deep FM 模型</li>
<li>Deep FFM模型</li>
</ul>
<a id="more"></a>
<h2 id="fm模型的引入-广告特征的稀疏性">FM模型的引入-广告特征的稀疏性</h2>
<p>FM（Factorization machines）模型由Steffen Rendle于2010年提出，目的是解决稀疏数据下的特征组合问题。</p>
<p>在介绍FM模型之前，来看看稀疏数据的训练问题。</p>
<p>以广告CTR（click-through rate）点击率预测任务为例，假设有如下数据：</p>
<table>
<thead>
<tr class="header">
<th><strong>Clicked?</strong></th>
<th>Country</th>
<th>Day</th>
<th>Ad_type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>USA</td>
<td>26/11/15</td>
<td>Movie</td>
</tr>
<tr class="even">
<td>0</td>
<td>China</td>
<td>19/2/15</td>
<td>Game</td>
</tr>
<tr class="odd">
<td>1</td>
<td>China</td>
<td>26/11/15</td>
<td>Game</td>
</tr>
</tbody>
</table>
<p>第一列Clicked是类别标记，标记用户是否点击了该广告，而其余列则是特征（这里的三个特征都是类别类型），一般的，我们会对数据进行One-hot编码将类别特征转化为数值特征，转化后数据如下:</p>
<table style="width:100%;">
<colgroup>
<col style="width: 15%" />
<col style="width: 14%" />
<col style="width: 17%" />
<col style="width: 15%" />
<col style="width: 5%" />
<col style="width: 14%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Clicked?</strong></th>
<th>Country=USA</th>
<th>Country=China</th>
<th>Day=26/11/15</th>
<th>Day=19/2/15</th>
<th>Ad_type=Movie</th>
<th>Ad_type=Game</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>经过One-hot编码后，特征空间是十分稀疏的。特别的，某类别特征有m种不同的取值，则one-hot编码后就会被变为m维！当类别特征越多、类别特征的取值越多，其特征空间就更加稀疏。</p>
<p>此外，往往我们会将特征进行两两的组合，这是因为：</p>
<blockquote>
<p>通过观察大量的样本数据可以发现，某些特征经过关联之后，与label之间的相关性就会提高。例如，“USA”与“Thanksgiving”、“China”与“Chinese New Year”这样的关联特征，对用户的点击有着正向的影响。换句话说，来自“China”的用户很可能会在“Chinese New Year”有大量的浏览、购买行为，而在“Thanksgiving”却不会有特别的消费行为。这种关联特征与label的正向相关性在实际问题中是普遍存在的，如“化妆品”类商品与“女”性，“球类运动配件”的商品与“男”性，“电影票”的商品与“电影”品类偏好等。</p>
</blockquote>
<p>再比如，用户更常在饭点的时间下载外卖app，因此，引入两个特征的组合是非常有意义的。</p>
<p>如何表示两个特征的组合呢？一种直接的方法就是采用多项式模型来表示两个特征的组合，<span class="math inline">\(x_i\)</span>为<strong>第<span class="math inline">\(i\)</span>个特征的取值</strong>（注意和以往表示第<span class="math inline">\(i\)</span>个样本的特征向量的区别），<span class="math inline">\(x_ix_j\)</span>表示特征<span class="math inline">\(x_i\)</span>和<span class="math inline">\(x_j\)</span>的特征组合，其系数<span class="math inline">\(w_{ij}\)</span>即为我们学习的参数，也是<span class="math inline">\(x_ix_j\)</span>组合的重要程度： <span class="math display">\[
\hat y(\mathbf{x}) = w_0+ \sum_{i=1}^d w_i x_i + \sum_{i=1}^d \sum_{j=i+1}^d w_{ij} x_i x_j \tag{1-1}
\]</span> 式1-1也可以称为<strong>Poly2</strong>(degree-2 poly-nomial mappings)模型。注意到式子1-1中参数的个数是非常多的！一次项有d+1个，二次项（即组合特征的参数）共有<span class="math inline">\(\frac{d(d-1)}{2}\)</span>个，而参数与参数之间彼此独立，在稀疏场景下，二次项的训练是很困难的。因为要训练<span class="math inline">\(w_{ij}\)</span>，需要有大量的<span class="math inline">\(x_i\)</span>和<span class="math inline">\(x_j\)</span>都非零的样本（只有非零组合才有意义）。而样本本身是稀疏的，满足<span class="math inline">\(x_ix_j \ne 0\)</span>的样本会非常少，样本少则难以估计参数<span class="math inline">\(w_{ij}\)</span>，训练出来容易导致模型的过拟合。</p>
<p>为此，Rendle于2010年提出FM模型，它能很好的求解式1-1，其特点如下：</p>
<ul>
<li>FM模型<strong>可以在非常稀疏的情况下</strong>进行参数估计</li>
<li>FM模型是<strong>线性时间复杂度</strong>的，可以直接使用原问题进行求解，而且不用像SVM一样依赖支持向量。</li>
<li>FM模型是一个<strong>通用</strong>的模型，其训练数据的特征取值可以是任意实数。而其它最先进的分解模型对输入数据有严格的限制。FMs可以模拟MF、SVD++、PITF或FPMC模型。</li>
</ul>
<h2 id="fm模型">FM模型</h2>
<p>前面提到过，式1-1的参数难以训练时因为训练数据的稀疏性。对于不同的特征对<span class="math inline">\(x_i,x_j\)</span>和<span class="math inline">\(x_i,x_k\)</span>，式1-1认为是完全独立的，对参数<span class="math inline">\(w_{ij}\)</span>和<span class="math inline">\(w_{ik}\)</span>分别进行训练。而实际上并非如此，不同的特征之间进行组合并非完全独立，如下图所示:</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/fm-feaure-pair.png" alt="fm-feaure-pair" /><figcaption>fm-feaure-pair</figcaption>
</figure>
<p>回想矩阵分解，一个rating可以分解为user矩阵和item矩阵，如下图所示：</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/fm-matrix-factorization.png" alt="fm-matrix-factorization" /><figcaption>fm-matrix-factorization</figcaption>
</figure>
<p>分解后得到user和item矩阵的维度分别为<span class="math inline">\(nk\)</span>和<span class="math inline">\(km\)</span>，（k一般由用户指定），相比原来的rating矩阵，空间占用得到降低，并且分解后的user矩阵暗含着user偏好，Item矩阵暗含着item的属性，而user矩阵乘上item矩阵就是rating矩阵中用户对item的评分。</p>
<p>因此，参考矩阵分解的过程，FM模型也将式1-1的二次项参数<span class="math inline">\(w_{ij}\)</span>进行分解： <span class="math display">\[
\hat y(\mathbf{x}) = w_0+ \sum_{i=1}^d w_i x_i + \sum_{i=1}^d \sum_{j=i+1}^d ( \mathbf{v}_i \cdot \mathbf{v}_j ) x_i x_j \tag{2-1}
\]</span> 其中<span class="math inline">\(v_i\)</span>是第<span class="math inline">\(i\)</span>维特征的隐向量，其长度为<span class="math inline">\(k (k\ll d)\)</span>。 <span class="math inline">\((\mathbf{v}_i \cdot \mathbf{v}_j)\)</span>为内积，其乘积为原来的<span class="math inline">\(w_{ij}\)</span>，即 <span class="math inline">\(\hat w_{ij} = ( \mathbf{v}_i \cdot \mathbf{v}_j ) = \sum_{f=1}^kv_{i,f} \cdot v_{j,f}\)</span></p>
<p>为了方便说明，考虑下面的数据集（实际中应该进行one-hot编码，但并不影响此处的说明）：</p>
<table>
<thead>
<tr class="header">
<th>数据集</th>
<th>Clicked?</th>
<th>Publisher</th>
<th>Advertiser</th>
<th>Poly2参数</th>
<th>FM参数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>训练集</td>
<td>1</td>
<td>NBC</td>
<td>Nike</td>
<td><span class="math inline">\(w_{NBC, Nike}\)</span></td>
<td><span class="math inline">\(V_{NBC} \cdot V_{Nike}\)</span></td>
</tr>
<tr class="even">
<td>训练集</td>
<td>0</td>
<td>EPSN</td>
<td>Adidas</td>
<td><span class="math inline">\(w_{EPSN, Adidas}\)</span></td>
<td><span class="math inline">\(V_{EPSN} \cdot V_{Adidas}\)</span></td>
</tr>
<tr class="odd">
<td>测试集</td>
<td>?</td>
<td>NBC</td>
<td>Adidas</td>
<td><span class="math inline">\(w_{NBC, Adidas}\)</span></td>
<td><span class="math inline">\(V_{NBC} \cdot V_{Adidas}\)</span></td>
</tr>
</tbody>
</table>
<p>对于上面的训练集，没有（NBC，Adidas）组合，因此，Poly2模型就无法学习到参数<span class="math inline">\(w_{NBC, Adidas}\)</span>。而FM模型可以通过特征组合(NBC，Nike)、(EPSN，Adidas) 分别学习到隐向量<span class="math inline">\(V_{NBC}\)</span>和<span class="math inline">\(V_{Adidas}\)</span>，这样使得在测试集中得以进行预测。</p>
<p>更一般的，经过分解，式2-1的参数个数减少为<span class="math inline">\(kd\)</span>个，对比式1-1，参数个数大大减少。使用小的k，<strong>使得模型能够提高在稀疏情况下的泛化性能</strong>。此外，将<span class="math inline">\(w_{ij}\)</span>进行分解，使得不同的特征对不再是完全独立的，而它们的关联性可以用隐式因子表示，这将使得有更多的数据可以用于模型参数的学习。比如<span class="math inline">\(x_i,x_j\)</span>与<span class="math inline">\(x_i,x_k\)</span>的参数分别为：<span class="math inline">\(\langle\mathbf{v}_i, \mathbf{v}_j \rangle\)</span>和<span class="math inline">\(\langle\mathbf{v}_i, \mathbf{v}_k \rangle\)</span>，它们都可以用来学习<span class="math inline">\(\mathbf v_i\)</span>，更一般的，<strong>包含<span class="math inline">\(x_i x_j \ne 0 \&amp; i\ne j\)</span>的所有样本都能用来学习<span class="math inline">\(\mathbf v_i\)</span></strong>，很大程度上避免了数据稀疏性的影响。</p>
<p>此外，式2-1的复杂度可以从<span class="math inline">\(O(kd^2)\)</span>优化到<span class="math inline">\(O(kd)\)</span>： <span class="math display">\[
\begin{align*}
 &amp;\sum_{i=1}^d \sum_{j=i+1}^d \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j \\
 =&amp; \frac{1}{2} \sum_{i=1}^d\sum_{j=1}^d   \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j - \frac{1}{2}\sum_{i=1}^d \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_i\\
 =&amp; \frac{1}{2} \sum_{i=1}^d\sum_{j=1}^d\sum_{f=1}^k  v_{i,f}v_{j,f} x_i x_j - \frac{1}{2}\sum_{i=1}^d \sum_{f=1}^k  v_{i,f}v_{i,f}x_i x_i\\
 =&amp; \frac{1}{2} \sum_{f=1}^k \left(  \left(\sum_{i=1}^dv_{i,f}x_i  \right)  \left(\sum_{j=1}^dv_{j,f}x_j \right) - \sum_{i=1}^d v_{i,f}^2x_i^2\right) \\
 =&amp;\frac{1}{2} \sum_{f=1}^k \left(  \left(\sum_{i=1}^dv_{i,f}x_i  \right) ^2 - \sum_{i=1}^d v_{i,f}^2x_i^2\right) \tag{2-2}
 \end{align*}
\]</span> 可以看出，FM模型可以在线性的时间做出预测。</p>
<h3 id="fm模型学习">FM模型学习</h3>
<p>把2-2和2-1合并，得到等价的FM模型公式2-3： <span class="math display">\[
\hat y(\mathbf{x}) = w_0+ \sum_{i=1}^d w_i x_i + \frac{1}{2} \sum_{f=1}^k \left(  \left(\sum_{i=1}^dv_{i,f}x_i  \right) ^2 - \sum_{i=1}^d v_{i,f}^2x_i^2\right) \tag{2-3}
\]</span> FM模型可以使用梯度下降法进行学习，模型的梯度为： <span class="math display">\[
\frac{\partial}{\partial\theta} y (\mathbf{x}) = 
\left\{\begin{array}{ll} 
     1,   &amp; \text{if}\; \theta\; \text{is}\; w_0 \\ 
     x_i,  &amp; \text{if}\; \theta\; \text{is}\; w_i \\ 
     x_i \sum_{j=1}^d v_{j, f} x_j - v_{i, f} x_i^2,  &amp; \text{if}\; \theta\; \text{is}\; v_{i, f} 
\end{array}\right. \tag{2-4}
\]</span> 在2-4式中，<span class="math inline">\(\sum_{j=1}^d v_{j, f} x_j\)</span>只与<span class="math inline">\(f\)</span>有关而与<span class="math inline">\(i\)</span>无关，在每次迭代过程中，可以预先对所有<span class="math inline">\(f\)</span>的<span class="math inline">\(\sum_{j=1}^d v_{j, f} x_j\)</span>进行计算，复杂度<span class="math inline">\(O(kd)\)</span>，就能在常数时间<span class="math inline">\(O(1)\)</span>内得到<span class="math inline">\(v_{i,f}\)</span>的梯度。而对于其它参数<span class="math inline">\(w_0\)</span>和<span class="math inline">\(w_i\)</span>，显然也是在常数时间内计算梯度。此外，更新参数只需要<span class="math inline">\(O(1)\)</span>, 一共有<span class="math inline">\(1+d+kd\)</span>个参数，因此FM参数训练的复杂度也是<span class="math inline">\(O(kd)\)</span>。</p>
<p>所以说，FM模型是一种高效的模型，<strong>是线性时间复杂度的</strong>，可以在线性的时间做出训练和预测。</p>
<h2 id="ffm模型">FFM模型</h2>
<p>考虑下面的数据集：</p>
<table>
<thead>
<tr class="header">
<th>Clicked?</th>
<th>Publisher(P)</th>
<th>Advertiser(A)</th>
<th>Gender(G)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>EPSN</td>
<td>Nike</td>
<td>Male</td>
</tr>
<tr class="even">
<td>0</td>
<td>NBC</td>
<td>Adidas</td>
<td>Female</td>
</tr>
</tbody>
</table>
<p>对于第一条数据来说，FM模型的二次项为：<span class="math inline">\({\bf w}_{EPSN} \cdot {\bf w}_{Nike} + {\bf w}_{EPSN} \cdot {\bf w}_{Male} + {\bf w}_{Nike} \cdot {\bf w}_{Male}\)</span>。（这里只是把上面的v符合改成了w）每个特征只用一个隐向量来学习和其它特征的潜在影响。对于上面的例子中，Nike是广告主，Male是用户的性别，描述（EPSN，Nike）和（EPSN，Male）特征组合，FM模型都用同一个<span class="math inline">\({\bf w}_{ESPN}\)</span>，而实际上，ESPN作为广告商，其对广告主和用户性别的潜在影响可能是不同的。</p>
<p>因此，Yu-Chin Juan借鉴Michael Jahrer的论文（Ensemble of collaborative filtering and feature engineered models for click through rate prediction），将field概念引入FM模型。</p>
<p>field是什么呢？即相同性质的特征放在一个field。比如EPSN、NBC都是属于广告商field的，Nike、Adidas都是属于广告主field，Male、Female都是属于性别field的。简单的说，同一个类别特征进行one-hot编码后生成的数值特征都可以放在同一个field中，比如最开始的例子中Day=26/11/15 Day=19/2/15可以放于同一个field中。如果是数值特征而非类别，可以直接作为一个field。</p>
<p>引入了field后，对于刚才的例子来说，二次项变为：</p>
<p><span class="math display">\[
\underbrace{ {\bf w}_{EPSN, A} \cdot {\bf w}_{Nike, P} }_{P \times A} + \underbrace{ {\bf w}_{EPSN, G} \cdot {\bf w}_{Male,P} }_{P \times G} +  \underbrace{ { {\bf w}_{Nike, G} \cdot {\bf w}_{Male,A} } }_{A \times G}
\]</span></p>
<ul>
<li>对于特征组合（EPSN，Nike）来说，其隐向量采用的是<span class="math inline">\({\bf w}_{EPSN,A}\)</span>和<span class="math inline">\({\bf w}_{Nike, P}\)</span>，对于<span class="math inline">\({\bf w}_{EPSN,A}\)</span>这是因为Nike属于广告主（Advertiser）的field，而第二项<span class="math inline">\({\bf w}_{Nike, P}\)</span>则是EPSN是广告商（Publisher）的field。</li>
<li>再举个例子，对于特征组合（EPSN，Male）来说，<span class="math inline">\({\bf w}_{EPSN, G}\)</span> 是因为Male是用户性别(Gender)的field，而第二项<span class="math inline">\({\bf w}_{Male,P}\)</span>是因为EPSN是广告商（Publisher）的field。</li>
</ul>
<p>下面的图来自criteo，很好的表示了三个模型的区别</p>
<blockquote>
<p>For Poly2, a dedicated weight is learned for each feature pair:</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/poly2-model-example.png" alt="poly2-model-example" /><figcaption>poly2-model-example</figcaption>
</figure>
<p>For FMs, each feature has one latent vector, which is used to interact with any other latent vectors:</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/fm-model-example.png" alt="fm-model-example" /><figcaption>fm-model-example</figcaption>
</figure>
<p>For FFMs, each feature has several latent vectors, one of them is used depending on the field of the other feature:</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/ffm-model-example.png" alt="ffm-model-example" /><figcaption>ffm-model-example</figcaption>
</figure>
</blockquote>
<h3 id="ffm-数学公式">FFM 数学公式</h3>
<p>因此，FFM的数学公式表示为： <span class="math display">\[
y(\mathbf{x}) = w_0 + \sum_{i=1}^d w_i x_i + \sum_{i=1}^d \sum_{j=i+1}^d (w_{i, f_j} \cdot w_{j, f_i}) x_i x_j  \tag{3-1}
\]</span> 其中<span class="math inline">\(f_i\)</span>和<span class="math inline">\(f_j\)</span>分别代表第i个特征和第j个特征所属的field。若field有<span class="math inline">\(f\)</span>个，隐向量的长度为k，则二次项系数共有<span class="math inline">\(dfk\)</span>个，远多于FM模型的<span class="math inline">\(dk\)</span>个。此外，隐向量和field相关，并不能像FM模型一样将二次项化简，计算的复杂度是<span class="math inline">\(d^2k\)</span>。</p>
<p>通常情况下，每个隐向量只需要学习特定field的表示，所以有<span class="math inline">\(k_{FFM} \ll k_{FM}\)</span>。</p>
<h3 id="ffm-模型学习">FFM 模型学习</h3>
<p>为了方便推导，这里省略FFM的一次项和常数项，公式为： <span class="math display">\[
\phi(\mathbf{w}, \mathbf{x}) =\sum_{a=1}^d \sum_{b=a+1}^d ( w_{a, f_b} \cdot  w_{b, f_a}) x_a x_b\tag{3-2}
\]</span> FFM模型使用logistic loss作为损失函数，并加上L2正则项： <span class="math display">\[
\mathcal{L} = \sum_{i=1}^N\log\left(1 + \exp(-y_i\phi({\bf w}, {\bf x_i}))\right) + \frac{\lambda}{2} |\!|{\bf w}|\!|^2 \tag{3-3}
\]</span> 采用随机梯度下降来（SGD）来优化损失函数，因此，损失函数只采用单个样本的损失： <span class="math display">\[
\mathcal{L} =\log\left(1 + \exp(-y_i\phi({\bf w}, {\bf x}))\right) + \frac{\lambda}{2} |\!|{\bf w}|\!|^2 \tag{3-4}
\]</span> 对于每次迭代，选取一条数据<span class="math inline">\(({\bf x}, y)\)</span>，然后让L对<span class="math inline">\({\bf w}_{a,f_b}\)</span>和<span class="math inline">\({\bf w}_{b,f_a}\)</span>求偏导（注意，采用SGD上面的求和项就去掉了，只采用单个样本的损失），得： <span class="math display">\[
\begin{align*}
g_{a,f_b} \equiv \frac{\partial \mathcal{L} }{\partial  w_{a,f_b} } = \kappa\cdot w_{b, f_a} x_a x_b + \lambda w_{a,f_b}^2 \tag{3-5} \\
g_{b,f_a} \equiv \frac{\partial \mathcal{L} }{\partial  w_{b,f_a} } = \kappa\cdot w_{a, f_b} x_a x_b + \lambda w_{b,f_a}^2 \tag{3-6}\\
其中, \kappa = \frac{-y}{1+\exp(y\phi({\bf w,x}))}
\end{align*}
\]</span> 在具体的实现中，这里有两个trick，第一个trick是梯度的分步计算。 <span class="math display">\[
\mathcal{L} = \mathcal{L} _{err} + \mathcal{L} _{reg} = \log\left(1 + \exp(-y_i\phi({\bf w}, {\bf x}))\right) + \frac{\lambda}{2} |\!|{\bf w}|\!|^2\\
\frac{\partial\mathcal{L} }{\partial\mathbf{w} } = \frac{\partial\mathcal{L}_{err} }{\partial\phi}\cdot \frac{\partial\phi}{\partial\mathbf{w} } + \frac{\partial\mathcal{L}_{reg} }{\partial\mathbf{w} }
\]</span> 注意到<span class="math inline">\(\frac{\partial\mathcal{L}_{err} }{\partial\phi}\)</span>和参数无关，每次更新模型时，只需要计算一次，之后直接调用结果即可。对于总共有<span class="math inline">\(dfk\)</span>个模型参数的计算来说，使用这种方式能极大提升运算效率。</p>
<p>第二个trick是FFM的学习率是随迭代次数变化的，具体的是采用<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad">AdaGrad</a>算法，这里进行简单的介绍。</p>
<p>Adagrad算法能够在训练中自动的调整学习率，<strong>对于稀疏的参数增加学习率，而稠密的参数则降低学习率。因此，Adagrad非常适合处理稀疏数据。</strong></p>
<p>设<span class="math inline">\(g_{t,j}\)</span>为第t轮第j个参数的梯度，则SGD和采用Adagrad的参数更新公式分别如下： <span class="math display">\[
\begin{align*}
SGD: \ &amp; w_{t+1,j} = w_{t,j} -\eta \cdot g_{t,j} \\
Adagrad: \ &amp; w_{t+1,j} = w_{t,j} - \frac{\eta}{\sqrt{G_{t,jj}+ \epsilon} } \cdot g_{t,j} 
\end{align*}
\]</span> 可以看出，Adagrad在学习率<span class="math inline">\(\eta\)</span>上还除以一项<span class="math inline">\(\sqrt{G_{t,jj}+ \epsilon}\)</span>，这是什么意思呢？<span class="math inline">\(\epsilon\)</span>为平滑项，防止分母为0，<span class="math inline">\(G_{t,jj} = \sum_{\iota=1}^tg_{\iota, jj}^2\)</span>即<span class="math inline">\(G_{t,jj}\)</span>为对角矩阵，每个对角线位置<span class="math inline">\(j,j\)</span>的值为参数<span class="math inline">\(w_j\)</span>每一轮的平方和，可以看出，随着迭代的进行，每个参数的历史梯度累加到一起，使得每个参数的学习率逐渐减小。</p>
<p>因此，用3-5、3-6计算完梯度后，下一步就是更新分母的对角矩阵。 <span class="math display">\[
\begin{align*}
G_{a,f_b} \leftarrow G_{a,f_b} + (g_{a,f_b})^2 \tag{3-7}\\
G_{b,f_a} \leftarrow G_{b,f_a} + (g_{b,f_a})^2  \tag{3-8}
\end{align*}
\]</span> 最后，更新模型参数： <span class="math display">\[
\begin{align*}
w_{a,f_b} &amp;\leftarrow w_{a,f_b} - \frac{\eta}{\sqrt{G_{a,f_b}+ 1} }g_{a,f_b} \tag{3-9}\\
w_{b,f_a} &amp;\leftarrow w_{b,f_a} -  \frac{\eta}{\sqrt{G_{b,f_a}+ 1} }g_{b,f_a}  \tag{3-10}
\end{align*}
\]</span> 这就是论文中算法1描述的过程：</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/ffm-model-training.png" alt="ffm-model-training" /><figcaption>ffm-model-training</figcaption>
</figure>
<h3 id="实现的trick">实现的trick</h3>
<p>本小节主要摘录美团点评的内容。</p>
<p>除了上面提到的梯度分步计算和自适应学习率两个trick外，还有：</p>
<blockquote>
<ol type="1">
<li>OpenMP多核并行计算。OpenMP是用于共享内存并行系统的多处理器程序设计的编译方案，便于移植和多核扩展[<a target="_blank" rel="noopener" href="http://openmp.org/wp/openmp-specifications/">12]</a>。FFM的源码采用了OpenMP的API，对参数训练过程SGD进行了多线程扩展，支持多线程编译。因此，OpenMP技术极大地提高了FFM的训练效率和多核CPU的利用率。在训练模型时，输入的训练参数ns_threads指定了线程数量，一般设定为CPU的核心数，便于完全利用CPU资源。</li>
<li>SSE3指令并行编程。SSE3全称为数据流单指令多数据扩展指令集3，是CPU对数据层并行的关键指令，主要用于多媒体和游戏的应用程序中[<a target="_blank" rel="noopener" href="http://blog.csdn.net/gengshenghong/article/details/7008704">13]</a>。SSE3指令采用128位的寄存器，同时操作4个单精度浮点数或整数。SSE3指令的功能非常类似于向量运算。例如，a和b采用SSE3指令相加（a和b分别包含4个数据），其功能是a种的4个元素与b中4个元素对应相加，得到4个相加后的值。采用SSE3指令后，向量运算的速度更加快捷，这对包含大量向量运算的FFM模型是非常有利的。</li>
</ol>
<p>除了上面的技巧之外，FFM的实现中还有很多调优技巧需要探索。例如，代码是按field和特征的编号申请参数空间的，如果选取了非连续或过大的编号，就会造成大量的内存浪费；在每个样本中加入值为1的新特征，相当于引入了因子化的一次项，避免了缺少一次项带来的模型偏差等。</p>
</blockquote>
<h3 id="适用范围和使用技巧">适用范围和使用技巧</h3>
<p>在FFM原论文中，作者指出，FFM模型对于one-hot后类别特征十分有效，但是如果数据不够稀疏，可能相比其它模型提升没有稀疏的时候那么大，此外，对于数值型的数据效果不是特别的好。</p>
<p>在Github上有FFM的<a target="_blank" rel="noopener" href="https://github.com/guestwalk/libffm">开源实现</a>，要使用FFM模型，特征需要转化为“<strong>field_id:feature_id:value</strong>”格式，相比LibSVM的格式多了field_id，即特征所属的field的编号，feature_id是特征编号，value为特征的值。</p>
<p>此外，美团点评的文章中，提到了训练FFM时的一些注意事项：</p>
<blockquote>
<p>第一，样本归一化。FFM默认是进行样本数据的归一化的 。若不进行归一化，很容易造成数据inf溢出，进而引起梯度计算的nan错误。因此，样本层面的数据是推荐进行归一化的。</p>
<p>第二，特征归一化。CTR/CVR模型采用了多种类型的源特征，包括数值型和categorical类型等。但是，categorical类编码后的特征取值只有0或1，较大的数值型特征会造成样本归一化后categorical类生成特征的值非常小，没有区分性。例如，一条用户-商品记录，用户为“男”性，商品的销量是5000个（假设其它特征的值为零），那么归一化后特征“sex=male”（性别为男）的值略小于0.0002，而“volume”（销量）的值近似为1。特征“sex=male”在这个样本中的作用几乎可以忽略不计，这是相当不合理的。因此，将源数值型特征的值归一化到[0,1]是非常必要的。</p>
<p>第三，省略零值特征。从FFM模型的表达式(3-1)可以看出，零值特征对模型完全没有贡献。包含零值特征的一次项和组合项均为零，对于训练模型参数或者目标值预估是没有作用的。因此，可以省去零值特征，提高FFM模型训练和预测的速度，这也是稀疏样本采用FFM的显著优势。</p>
</blockquote>
<h2 id="deepfm">DeepFM</h2>
<p>FM模型可以用神经网络进行表示<sup>[3]</sup>：</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/deep-fm-part.png" alt="deep-fm-part" /><figcaption>deep-fm-part</figcaption>
</figure>
<p>模型输入<span class="math inline">\(x = [x_{field_1}, x_{field_2}, \cdots, x_{field_m}]\)</span>，这是一个d维的向量，其中<span class="math inline">\(x_{field_i}\)</span>即为第i个field的特征表示，如果是类别，则为one-hot编码后的向量，连续值则为它本身。</p>
<p>然后对每个field分别进行embedding，如下图：</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/deep-embedding.png" alt="deep-embedding" /><figcaption>deep-embedding</figcaption>
</figure>
<p>值得注意的是，即使各个field的维度是不一样的，但是它们embedding后<strong>长度均为k</strong>。</p>
<p>接着FM层即为embedding后结果的内积和一次项的和，最后一层sigmoid后再输出结果。</p>
<p>看到这里，可能你感到困惑的就是embedding层，这么表示是为啥？答案是这样表示和fm模型等价！</p>
<p>假设第i个field 向量维度为k，embedding层的参数可以表示为一个k * m的矩阵 <span class="math display">\[
V_{field_i}= \begin{bmatrix} 
v_{11} &amp; v_{21} &amp; \cdots &amp; v_{m1} \\ 
v_{12} &amp; v_{22} &amp; \cdots &amp; v_{m2} \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 
v_{1k} &amp; v_{2k} &amp; \cdots &amp; v_{md} \\ 
\end{bmatrix}
\]</span> 其中<span class="math inline">\(v_{ab}\)</span>可以理解为第a个取值embedding后的结果在隐向量的第b维。</p>
<p>由于进行了one-hot编码，所以对应的<span class="math inline">\(\bf x_{filed_i}\)</span>只有一个值为1，其余的都为0,假设第c列为1，则： <span class="math display">\[
V_{field_i}\times {\bf x_{field_i} }=\begin{bmatrix} 
v_{11} &amp; v_{21} &amp; \cdots &amp; v_{m1} \\ 
v_{12} &amp; v_{22} &amp; \cdots &amp; v_{m2} \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 
v_{1k} &amp; v_{2k} &amp; \cdots &amp; v_{md} \\ 
\end{bmatrix} \times \begin{bmatrix} 0 \\ \vdots \\1\\ \vdots \\ \end{bmatrix}
=  \begin{bmatrix} v_{c1}\\ v_{c2} \\ \vdots \\ v_{ck} \end{bmatrix} x_c= V_c x_c
\]</span> 若两个field做内积，假设非0的那一列为c和d则： <span class="math display">\[
(V_{field_i} \ x_{field_i})   (V_ {field_j}\ x_{field_j})=( \mathbf{V}_c \cdot \mathbf{V}_d ) x_c x_d
\]</span> 其实和FM模型是一样的！</p>
<p>DeepFM的模型如下图：</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/deep-fm.png" alt="deep-fm" /><figcaption>deep-fm</figcaption>
</figure>
<p>左边就是刚才将的FM模型的神经网络表示，而右边的则为deep部分，为全连接的网络，用于挖掘高阶的交叉特征。整个模型共享embedding层，最后的结果就是把FM部分和DNN的部分做sigmoid： <span class="math display">\[
Y = sigmoid(Y_{FM} + Y_{DNN})
\]</span></p>
<h2 id="deepffm">DeepFFM</h2>
<p>类似于FFM对于FM模型来说，划分了field，对于不同的field内积时采用对应的隐向量。同样可以把DeepFM进行进化为DeepFFM，即将每一个field embedding为m个维度为k的隐向量（m为field的个数）</p>
<p>可以参考下图（不过下图没有FFM模型二次项的乘积，实际中也可以加上）</p>
<figure>
<img src="../images/machine-learning-fm-ffm-deepfm-deepffm/deep-ffm.jpg" alt="deep-ffm" /><figcaption>deep-ffm</figcaption>
</figure>
<h2 id="参考资料">参考资料</h2>
<ol type="1">
<li>Rendle, Steffen. &quot;Factorization machines.&quot; <em>Data Mining (ICDM), 2010 IEEE 10th International Conference on</em>. IEEE, 2010.</li>
<li>Juan, Yuchin, et al. &quot;Field-aware factorization machines for CTR prediction.&quot; <em>Proceedings of the 10th ACM Conference on Recommender Systems</em>. ACM, 2016.</li>
<li>Guo, Huifeng, et al. &quot;Deepfm: A factorization-machine based neural network for CTR prediction.&quot; <em>arXiv preprint arXiv:1703.04247</em> (2017).</li>
<li><a target="_blank" rel="noopener" href="https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html">深入FFM原理与实践</a></li>
<li><a target="_blank" rel="noopener" href="http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf">Factorization Machines</a></li>
<li><a target="_blank" rel="noopener" href="http://research.criteo.com/ctr-prediction-linear-model-field-aware-factorization-machines/">CTR Prediction: From Linear Models to Field-aware Factorization Machines</a></li>
</ol>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>hrwhisper
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://www.hrwhisper.me/machine-learning-fm-ffm-deepfm-deepffm/" title="『我爱机器学习』FM、FFM与DeepFM">https://www.hrwhisper.me/machine-learning-fm-ffm-deepfm-deepffm/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        <div class="reward-container">
  <div>请我喝杯咖啡吧~</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/donate/wechat_pay.png" alt="hrwhisper 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/donate/alipay.jpg" alt="hrwhisper 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
              <a href="/tags/Machine-Learning-model/" rel="tag"># Machine Learning model</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/machine-learning-lightgbm/" rel="prev" title="『我爱机器学习』集成学习（四）LightGBM">
      <i class="fa fa-chevron-left"></i> 『我爱机器学习』集成学习（四）LightGBM
    </a></div>
      <div class="post-nav-item">
    <a href="/machine-learning-maximum-entropy-model/" rel="next" title="『我爱机器学习』最大熵原理与最大熵模型">
      『我爱机器学习』最大熵原理与最大熵模型 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#fm%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BC%95%E5%85%A5-%E5%B9%BF%E5%91%8A%E7%89%B9%E5%BE%81%E7%9A%84%E7%A8%80%E7%96%8F%E6%80%A7"><span class="nav-text">FM模型的引入-广告特征的稀疏性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fm%E6%A8%A1%E5%9E%8B"><span class="nav-text">FM模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#fm%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0"><span class="nav-text">FM模型学习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ffm%E6%A8%A1%E5%9E%8B"><span class="nav-text">FFM模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ffm-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F"><span class="nav-text">FFM 数学公式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ffm-%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0"><span class="nav-text">FFM 模型学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E7%9A%84trick"><span class="nav-text">实现的trick</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%82%E7%94%A8%E8%8C%83%E5%9B%B4%E5%92%8C%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7"><span class="nav-text">适用范围和使用技巧</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#deepfm"><span class="nav-text">DeepFM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#deepffm"><span class="nav-text">DeepFFM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-text">参考资料</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="hrwhisper"
      src="/images/site/avatar.jpg">
  <p class="site-author-name" itemprop="name">hrwhisper</p>
  <div class="site-description" itemprop="description">一个分享机器学习、算法与数据结构，个人学习心得、读书笔记、生活的博客。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">253</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/hrwhisper" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hrwhisper" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/murmured" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;murmured" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
      <script data-ad-client="ca-pub-1580254183546533" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2013 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hrwhisper</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"fVcjWMD8aI6F0qEfKdUaHa4f-gzGzoHsz","app_key":"b26lBsbwmVyxTSnNrsBrnv3U","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
      script.defer = true;
      // script.setAttribute("data-pjax", "");
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'fVcjWMD8aI6F0qEfKdUaHa4f-gzGzoHsz',
      appKey     : 'b26lBsbwmVyxTSnNrsBrnv3U',
      placeholder: "在上方填上邮箱地址可以收到我回复的邮件哦~",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
