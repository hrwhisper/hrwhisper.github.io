<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
   
  <meta name="keywords" content="c,c++,java,python,leetcode,algorithm,reading,life,moods,machine-learning,data-mining,deep-learning,AI" />
   
  <meta name="description" content="一个分享机器学习、算法与数据结构，个人学习心得、读书笔记、生活的博客。" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    『我爱机器学习』FM、FFM与DeepFM |  一个分享机器学习、算法与数据结构，个人学习心得、读书笔记、生活的博客。
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

</head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-machine-learning-fm-ffm-deepfm-deepffm"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  『我爱机器学习』FM、FFM与DeepFM
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/machine-learning-fm-ffm-deepfm-deepffm/" class="article-date">
  <time datetime="2018-06-15T03:48:57.000Z" itemprop="datePublished">2018-06-15</time>
</a> 
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a> / <a class="article-category-link" href="/categories/study/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>
 
       
        
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">5.6k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">23 min</span>
        </span>
    </span>
</div>

      
       
        <div class="word_count">
    <span class="post-meta-item-icon">
        <i class="ri-eye-fill"></i> 
        阅读数:<span id="/machine-learning-fm-ffm-deepfm-deepffm/" data-flag-title="『我爱机器学习』FM、FFM与DeepFM" class="leancloud_visitors">0</span>次
    </span>
</div>
      
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>FM和FMM模型在数据量比较大并且特征稀疏的情况下，仍然有优秀的性能表现，在CTR/CVR任务上尤其突出。</p>
<p>近些年来，深度学习的方法也开始应用在广告计算领域，因此本文也会对FM和FFM的深度学习版本做一个介绍。</p>
<p>本文包括：</p>
<ul>
<li>FM 模型</li>
<li>FFM 模型</li>
<li>Deep FM 模型</li>
<li>Deep FFM模型</li>
</ul>
<a id="more"></a>
<h2 id="FM模型的引入-广告特征的稀疏性"><a href="#FM模型的引入-广告特征的稀疏性" class="headerlink" title="FM模型的引入-广告特征的稀疏性"></a>FM模型的引入-广告特征的稀疏性</h2><p>FM（Factorization machines）模型由Steffen Rendle于2010年提出，目的是解决稀疏数据下的特征组合问题。</p>
<p>在介绍FM模型之前，来看看稀疏数据的训练问题。</p>
<p>以广告CTR（click-through rate）点击率预测任务为例，假设有如下数据：</p>
<div class="table-responsive">

| **Clicked?** | Country | Day      | Ad_type |
| ------ | ------- | -------- | ------- |
| 1            | USA     | 26/11/15 | Movie   |
| 0            | China   | 19/2/15   | Game    |
| 1            | China   | 26/11/15  | Game    |

</div>
第一列Clicked是类别标记，标记用户是否点击了该广告，而其余列则是特征（这里的三个特征都是类别类型），一般的，我们会对数据进行One-hot编码将类别特征转化为数值特征，转化后数据如下:

<div class="table-responsive">

| **Clicked?** | Country=USA | Country=China | Day=26/11/15 |     Day=19/2/15 | Ad_type=Movie | Ad_type=Game |
| ------------ | ----------- | ------------- | ------------ | ---- | ----------- | ------------- |
| 1            | 1           | 0             | 1            | 0 | 1          | 0            |
| 0            | 0           | 1             | 0            | 1 | 0           | 1            |
| 1            | 0           | 1             | 1            | 0 | 0          | 1            |

</div>
经过One-hot编码后，特征空间是十分稀疏的。特别的，某类别特征有m种不同的取值，则one-hot编码后就会被变为m维！当类别特征越多、类别特征的取值越多，其特征空间就更加稀疏。

此外，往往我们会将特征进行两两的组合，这是因为：

> 通过观察大量的样本数据可以发现，某些特征经过关联之后，与label之间的相关性就会提高。例如，“USA”与“Thanksgiving”、“China”与“Chinese New Year”这样的关联特征，对用户的点击有着正向的影响。换句话说，来自“China”的用户很可能会在“Chinese New Year”有大量的浏览、购买行为，而在“Thanksgiving”却不会有特别的消费行为。这种关联特征与label的正向相关性在实际问题中是普遍存在的，如“化妆品”类商品与“女”性，“球类运动配件”的商品与“男”性，“电影票”的商品与“电影”品类偏好等。

再比如，用户更常在饭点的时间下载外卖app，因此，引入两个特征的组合是非常有意义的。

如何表示两个特征的组合呢？一种直接的方法就是采用多项式模型来表示两个特征的组合，$x_i$为**第$i$个特征的取值**（注意和以往表示第$i$个样本的特征向量的区别），$x_ix_j$表示特征$x_i$和$x_j$的特征组合，其系数$w_{ij}$即为我们学习的参数，也是$x_ix_j$组合的重要程度：
$$
\hat y(\mathbf{x}) = w_0+ \sum_{i=1}^d w_i x_i + \sum_{i=1}^d \sum_{j=i+1}^d w_{ij} x_i x_j \tag{1-1}
$$
式1-1也可以称为**Poly2**(degree-2 poly-nomial mappings)模型。注意到式子1-1中参数的个数是非常多的！一次项有d+1个，二次项（即组合特征的参数）共有$\frac{d(d-1)}{2}$个，而参数与参数之间彼此独立，在稀疏场景下，二次项的训练是很困难的。因为要训练$w_{ij}$，需要有大量的$x_i$和$x_j$都非零的样本（只有非零组合才有意义）。而样本本身是稀疏的，满足$x_ix_j \ne 0$的样本会非常少，样本少则难以估计参数$w_{ij}$，训练出来容易导致模型的过拟合。

为此，Rendle于2010年提出FM模型，它能很好的求解式1-1，其特点如下：

- FM模型**可以在非常稀疏的情况下**进行参数估计
- FM模型是**线性时间复杂度**的，可以直接使用原问题进行求解，而且不用像SVM一样依赖支持向量。
- FM模型是一个**通用**的模型，其训练数据的特征取值可以是任意实数。而其它最先进的分解模型对输入数据有严格的限制。FMs可以模拟MF、SVD++、PITF或FPMC模型。





## FM模型

前面提到过，式1-1的参数难以训练时因为训练数据的稀疏性。对于不同的特征对$x_i,x_j$和$x_i,x_k$，式1-1认为是完全独立的，对参数$w_{ij}$和$w_{ik}$分别进行训练。而实际上并非如此，不同的特征之间进行组合并非完全独立，如下图所示:

![fm-feaure-pair](../images/machine-learning-fm-ffm-deepfm-deepffm/fm-feaure-pair.png)

回想矩阵分解，一个rating可以分解为user矩阵和item矩阵，如下图所示：

![fm-matrix-factorization](../images/machine-learning-fm-ffm-deepfm-deepffm/fm-matrix-factorization.png)

分解后得到user和item矩阵的维度分别为$nk$和$km$，（k一般由用户指定），相比原来的rating矩阵，空间占用得到降低，并且分解后的user矩阵暗含着user偏好，Item矩阵暗含着item的属性，而user矩阵乘上item矩阵就是rating矩阵中用户对item的评分。

因此，参考矩阵分解的过程，FM模型也将式1-1的二次项参数$w_{ij}$进行分解：
$$
\hat y(\mathbf{x}) = w_0+ \sum_{i=1}^d w_i x_i + \sum_{i=1}^d \sum_{j=i+1}^d ( \mathbf{v}_i \cdot \mathbf{v}_j ) x_i x_j \tag{2-1}
$$
其中$v_i$是第$i$维特征的隐向量，其长度为$k (k\ll d)$。 $(\mathbf{v}_i \cdot \mathbf{v}_j)$为内积，其乘积为原来的$w_{ij}$，即  $\hat w_{ij} = ( \mathbf{v}_i \cdot \mathbf{v}_j )   = \sum_{f=1}^kv_{i,f} \cdot v_{j,f}$

为了方便说明，考虑下面的数据集（实际中应该进行one-hot编码，但并不影响此处的说明）：
<div class="table-responsive">

| 数据集 | Clicked? | Publisher | Advertiser | Poly2参数          | FM参数                      |
| ------ | -------- | --------- | ---------- | ------------------ | --------------------------- |
| 训练集 | 1        | NBC       | Nike       | $w_{NBC, Nike}$    | $V_{NBC} \cdot V_{Nike}$    |
| 训练集 | 0        | EPSN      | Adidas     | $w_{EPSN, Adidas}$ | $V_{EPSN} \cdot V_{Adidas}$ |
| 测试集 | ?        | NBC       | Adidas     | $w_{NBC, Adidas}$  | $V_{NBC} \cdot V_{Adidas}$  |
</div>

<p>对于上面的训练集，没有（NBC，Adidas）组合，因此，Poly2模型就无法学习到参数$w_{NBC, Adidas}$。而FM模型可以通过特征组合(NBC，Nike)、(EPSN，Adidas) 分别学习到隐向量$V_{NBC}$和$V_{Adidas}$，这样使得在测试集中得以进行预测。</p>
<p>更一般的，经过分解，式2-1的参数个数减少为$kd$个，对比式1-1，参数个数大大减少。使用小的k，<strong>使得模型能够提高在稀疏情况下的泛化性能</strong>。此外，将$w_{ij}$进行分解，使得不同的特征对不再是完全独立的，而它们的关联性可以用隐式因子表示，这将使得有更多的数据可以用于模型参数的学习。比如$x_i,x_j$与$x_i,x_k$的参数分别为：$\langle\mathbf{v}_i, \mathbf{v}_j \rangle$和$\langle\mathbf{v}_i, \mathbf{v}_k \rangle$，它们都可以用来学习$\mathbf v_i$，更一般的，<strong>包含$x_i x_j \ne 0 \and i\ne j$的所有样本都能用来学习$\mathbf v_i$</strong>，很大程度上避免了数据稀疏性的影响。</p>
<p>此外，式2-1的复杂度可以从$O(kd^2)$优化到$O(kd)$：</p>
<script type="math/tex; mode=display">
\begin{align*}
 &\sum_{i=1}^d \sum_{j=i+1}^d \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j \\
 =& \frac{1}{2} \sum_{i=1}^d\sum_{j=1}^d   \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j - \frac{1}{2}\sum_{i=1}^d \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_i\\
 =& \frac{1}{2} \sum_{i=1}^d\sum_{j=1}^d\sum_{f=1}^k  v_{i,f}v_{j,f} x_i x_j - \frac{1}{2}\sum_{i=1}^d \sum_{f=1}^k  v_{i,f}v_{i,f}x_i x_i\\
 =& \frac{1}{2} \sum_{f=1}^k \left(  \left(\sum_{i=1}^dv_{i,f}x_i  \right)  \left(\sum_{j=1}^dv_{j,f}x_j \right) - \sum_{i=1}^d v_{i,f}^2x_i^2\right) \\
 =&\frac{1}{2} \sum_{f=1}^k \left(  \left(\sum_{i=1}^dv_{i,f}x_i  \right) ^2 - \sum_{i=1}^d v_{i,f}^2x_i^2\right) \tag{2-2}
 \end{align*}</script><p>可以看出，FM模型可以在线性的时间做出预测。</p>
<h3 id="FM模型学习"><a href="#FM模型学习" class="headerlink" title="FM模型学习"></a>FM模型学习</h3><p>把2-2和2-1合并，得到等价的FM模型公式2-3：</p>
<script type="math/tex; mode=display">
\hat y(\mathbf{x}) = w_0+ \sum_{i=1}^d w_i x_i + \frac{1}{2} \sum_{f=1}^k \left(  \left(\sum_{i=1}^dv_{i,f}x_i  \right) ^2 - \sum_{i=1}^d v_{i,f}^2x_i^2\right) \tag{2-3}</script><p>FM模型可以使用梯度下降法进行学习，模型的梯度为：</p>
<script type="math/tex; mode=display">
\frac{\partial}{\partial\theta} y (\mathbf{x}) = 
\left\{\begin{array}{ll} 
     1,   & \text{if}\; \theta\; \text{is}\; w_0 \\ 
     x_i,  & \text{if}\; \theta\; \text{is}\; w_i \\ 
     x_i \sum_{j=1}^d v_{j, f} x_j - v_{i, f} x_i^2,  & \text{if}\; \theta\; \text{is}\; v_{i, f} 
\end{array}\right. \tag{2-4}</script><p>在2-4式中，$\sum_{j=1}^d v_{j, f} x_j$只与$f$有关而与$i$无关，在每次迭代过程中，可以预先对所有$f$的$\sum_{j=1}^d v_{j, f} x_j$进行计算，复杂度$O(kd)$，就能在常数时间$O(1)$内得到$v_{i,f}$的梯度。而对于其它参数$w_0$和$w_i$，显然也是在常数时间内计算梯度。此外，更新参数只需要$O(1)$, 一共有$1+d+kd$个参数，因此FM参数训练的复杂度也是$O(kd)$。</p>
<p>所以说，FM模型是一种高效的模型，<strong>是线性时间复杂度的</strong>，可以在线性的时间做出训练和预测。</p>
<h2 id="FFM模型"><a href="#FFM模型" class="headerlink" title="FFM模型"></a>FFM模型</h2><p>考虑下面的数据集：</p>
<div class="table-responsive">

| Clicked? | Publisher(P) | Advertiser(A) | Gender(G) |
| -------- | ------------ | ------------- | --------- |
| 1        | EPSN         | Nike          | Male      |
| 0        | NBC          | Adidas        | Female    |

</div>

<p>对于第一条数据来说，FM模型的二次项为：${\bf w}_{EPSN} \cdot {\bf w}_{Nike} + {\bf w}_{EPSN} \cdot {\bf w}_{Male} + {\bf w}_{Nike} \cdot {\bf w}_{Male}$。（这里只是把上面的v符合改成了w）每个特征只用一个隐向量来学习和其它特征的潜在影响。对于上面的例子中，Nike是广告主，Male是用户的性别，描述（EPSN，Nike）和（EPSN，Male）特征组合，FM模型都用同一个${\bf w}_{ESPN}$，而实际上，ESPN作为广告商，其对广告主和用户性别的潜在影响可能是不同的。</p>
<p>因此，Yu-Chin Juan借鉴Michael Jahrer的论文（Ensemble of collaborative filtering and feature engineered models for click through rate prediction），将field概念引入FM模型。</p>
<p>field是什么呢？即相同性质的特征放在一个field。比如EPSN、NBC都是属于广告商field的，Nike、Adidas都是属于广告主field，Male、Female都是属于性别field的。简单的说，同一个类别特征进行one-hot编码后生成的数值特征都可以放在同一个field中，比如最开始的例子中Day=26/11/15  Day=19/2/15可以放于同一个field中。如果是数值特征而非类别，可以直接作为一个field。</p>
<p>引入了field后，对于刚才的例子来说，二次项变为：</p>
<script type="math/tex; mode=display">
\underbrace{ {\bf w}_{EPSN, A} \cdot {\bf w}_{Nike, P} }_{P \times A} + \underbrace{ {\bf w}_{EPSN, G} \cdot {\bf w}_{Male,P} }_{P \times G} +  \underbrace{ { {\bf w}_{Nike, G} \cdot {\bf w}_{Male,A} } }_{A \times G}</script><ul>
<li>对于特征组合（EPSN，Nike）来说，其隐向量采用的是${\bf w}_{EPSN,A}$和${\bf w}_{Nike, P}$，对于${\bf w}_{EPSN,A}$这是因为Nike属于广告主（Advertiser）的field，而第二项${\bf w}_{Nike, P}$则是EPSN是广告商（Publisher）的field。 </li>
<li>再举个例子，对于特征组合（EPSN，Male）来说，${\bf w}_{EPSN, G}$ 是因为Male是用户性别(Gender)的field，而第二项${\bf w}_{Male,P}$是因为EPSN是广告商（Publisher）的field。 </li>
</ul>
<p>下面的图来自criteo，很好的表示了三个模型的区别</p>
<blockquote>
<p>For Poly2, a dedicated weight is learned for each feature pair:</p>
<p><img src="../images/machine-learning-fm-ffm-deepfm-deepffm/poly2-model-example.png" alt="poly2-model-example"></p>
<p>For FMs, each feature has one latent vector, which is used to interact with any other latent vectors:</p>
<p><img src="../images/machine-learning-fm-ffm-deepfm-deepffm/fm-model-example.png" alt="fm-model-example"></p>
<p>For FFMs, each feature has several latent vectors, one of them is used depending on the field of the other feature:</p>
<p><img src="../images/machine-learning-fm-ffm-deepfm-deepffm/ffm-model-example.png" alt="ffm-model-example"></p>
</blockquote>
<h3 id="FFM-数学公式"><a href="#FFM-数学公式" class="headerlink" title="FFM 数学公式"></a>FFM 数学公式</h3><p>因此，FFM的数学公式表示为：</p>
<script type="math/tex; mode=display">
y(\mathbf{x}) = w_0 + \sum_{i=1}^d w_i x_i + \sum_{i=1}^d \sum_{j=i+1}^d (w_{i, f_j} \cdot w_{j, f_i}) x_i x_j  \tag{3-1}</script><p>其中$f_i$和$f_j$分别代表第i个特征和第j个特征所属的field。若field有$f$个，隐向量的长度为k，则二次项系数共有$dfk$个，远多于FM模型的$dk$个。此外，隐向量和field相关，并不能像FM模型一样将二次项化简，计算的复杂度是$d^2k$。</p>
<p>通常情况下，每个隐向量只需要学习特定field的表示，所以有$k_{FFM} \ll k_{FM}$。</p>
<h3 id="FFM-模型学习"><a href="#FFM-模型学习" class="headerlink" title="FFM 模型学习"></a>FFM 模型学习</h3><p>为了方便推导，这里省略FFM的一次项和常数项，公式为：</p>
<script type="math/tex; mode=display">
\phi(\mathbf{w}, \mathbf{x}) =\sum_{a=1}^d \sum_{b=a+1}^d ( w_{a, f_b} \cdot  w_{b, f_a}) x_a x_b\tag{3-2}</script><p>FFM模型使用logistic loss作为损失函数，并加上L2正则项：</p>
<script type="math/tex; mode=display">
\mathcal{L} = \sum_{i=1}^N\log\left(1 + \exp(-y_i\phi({\bf w}, {\bf x_i}))\right) + \frac{\lambda}{2} |\!|{\bf w}|\!|^2 \tag{3-3}</script><p>采用随机梯度下降来（SGD）来优化损失函数，因此，损失函数只采用单个样本的损失：</p>
<script type="math/tex; mode=display">
\mathcal{L} =\log\left(1 + \exp(-y_i\phi({\bf w}, {\bf x}))\right) + \frac{\lambda}{2} |\!|{\bf w}|\!|^2 \tag{3-4}</script><p>对于每次迭代，选取一条数据$({\bf x}, y)$，然后让L对${\bf w}_{a,f_b}$和${\bf w}_{b,f_a}$求偏导（注意，采用SGD上面的求和项就去掉了，只采用单个样本的损失），得：</p>
<script type="math/tex; mode=display">
\begin{align*}
g_{a,f_b} \equiv \frac{\partial \mathcal{L} }{\partial  w_{a,f_b} } = \kappa\cdot w_{b, f_a} x_a x_b + \lambda w_{a,f_b}^2 \tag{3-5} \\
g_{b,f_a} \equiv \frac{\partial \mathcal{L} }{\partial  w_{b,f_a} } = \kappa\cdot w_{a, f_b} x_a x_b + \lambda w_{b,f_a}^2 \tag{3-6}\\
其中, \kappa = \frac{-y}{1+\exp(y\phi({\bf w,x}))}
\end{align*}</script><p>在具体的实现中，这里有两个trick，第一个trick是梯度的分步计算。</p>
<script type="math/tex; mode=display">
\mathcal{L} = \mathcal{L} _{err} + \mathcal{L} _{reg} = \log\left(1 + \exp(-y_i\phi({\bf w}, {\bf x}))\right) + \frac{\lambda}{2} |\!|{\bf w}|\!|^2\\
\frac{\partial\mathcal{L} }{\partial\mathbf{w} } = \frac{\partial\mathcal{L}_{err} }{\partial\phi}\cdot \frac{\partial\phi}{\partial\mathbf{w} } + \frac{\partial\mathcal{L}_{reg} }{\partial\mathbf{w} }</script><p>注意到$\frac{\partial\mathcal{L}_{err} }{\partial\phi}$和参数无关，每次更新模型时，只需要计算一次，之后直接调用结果即可。对于总共有$dfk$个模型参数的计算来说，使用这种方式能极大提升运算效率。</p>
<p>第二个trick是FFM的学习率是随迭代次数变化的，具体的是采用<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad">AdaGrad</a>算法，这里进行简单的介绍。</p>
<p>Adagrad算法能够在训练中自动的调整学习率，<strong>对于稀疏的参数增加学习率，而稠密的参数则降低学习率。因此，Adagrad非常适合处理稀疏数据。</strong> </p>
<p>设$g_{t,j}$为第t轮第j个参数的梯度，则SGD和采用Adagrad的参数更新公式分别如下：</p>
<script type="math/tex; mode=display">
\begin{align*}
SGD: \ & w_{t+1,j} = w_{t,j} -\eta \cdot g_{t,j} \\
Adagrad: \ & w_{t+1,j} = w_{t,j} - \frac{\eta}{\sqrt{G_{t,jj}+ \epsilon} } \cdot g_{t,j} 
\end{align*}</script><p>可以看出，Adagrad在学习率$\eta$上还除以一项$\sqrt{G_{t,jj}+ \epsilon}$，这是什么意思呢？$\epsilon$为平滑项，防止分母为0，$G_{t,jj} = \sum_{\iota=1}^tg_{\iota, jj}^2$即$G_{t,jj}$为对角矩阵，每个对角线位置$j,j$的值为参数$w_j$每一轮的平方和，可以看出，随着迭代的进行，每个参数的历史梯度累加到一起，使得每个参数的学习率逐渐减小。</p>
<p>因此，用3-5、3-6计算完梯度后，下一步就是更新分母的对角矩阵。</p>
<script type="math/tex; mode=display">
\begin{align*}
G_{a,f_b} \leftarrow G_{a,f_b} + (g_{a,f_b})^2 \tag{3-7}\\
G_{b,f_a} \leftarrow G_{b,f_a} + (g_{b,f_a})^2  \tag{3-8}
\end{align*}</script><p>最后，更新模型参数：</p>
<script type="math/tex; mode=display">
\begin{align*}
w_{a,f_b} &\leftarrow w_{a,f_b} - \frac{\eta}{\sqrt{G_{a,f_b}+ 1} }g_{a,f_b} \tag{3-9}\\
w_{b,f_a} &\leftarrow w_{b,f_a} -  \frac{\eta}{\sqrt{G_{b,f_a}+ 1} }g_{b,f_a}  \tag{3-10}
\end{align*}</script><p>这就是论文中算法1描述的过程：</p>
<p><img src="../images/machine-learning-fm-ffm-deepfm-deepffm/ffm-model-training.png" alt="ffm-model-training"></p>
<h3 id="实现的trick"><a href="#实现的trick" class="headerlink" title="实现的trick"></a>实现的trick</h3><p>本小节主要摘录美团点评的内容。</p>
<p>除了上面提到的梯度分步计算和自适应学习率两个trick外，还有：</p>
<blockquote>
<ol>
<li>OpenMP多核并行计算。OpenMP是用于共享内存并行系统的多处理器程序设计的编译方案，便于移植和多核扩展<a target="_blank" rel="noopener" href="http://openmp.org/wp/openmp-specifications/">[12]</a>。FFM的源码采用了OpenMP的API，对参数训练过程SGD进行了多线程扩展，支持多线程编译。因此，OpenMP技术极大地提高了FFM的训练效率和多核CPU的利用率。在训练模型时，输入的训练参数ns_threads指定了线程数量，一般设定为CPU的核心数，便于完全利用CPU资源。</li>
<li>SSE3指令并行编程。SSE3全称为数据流单指令多数据扩展指令集3，是CPU对数据层并行的关键指令，主要用于多媒体和游戏的应用程序中<a target="_blank" rel="noopener" href="http://blog.csdn.net/gengshenghong/article/details/7008704">[13]</a>。SSE3指令采用128位的寄存器，同时操作4个单精度浮点数或整数。SSE3指令的功能非常类似于向量运算。例如，a和b采用SSE3指令相加（a和b分别包含4个数据），其功能是a种的4个元素与b中4个元素对应相加，得到4个相加后的值。采用SSE3指令后，向量运算的速度更加快捷，这对包含大量向量运算的FFM模型是非常有利的。</li>
</ol>
<p>除了上面的技巧之外，FFM的实现中还有很多调优技巧需要探索。例如，代码是按field和特征的编号申请参数空间的，如果选取了非连续或过大的编号，就会造成大量的内存浪费；在每个样本中加入值为1的新特征，相当于引入了因子化的一次项，避免了缺少一次项带来的模型偏差等。</p>
</blockquote>
<h3 id="适用范围和使用技巧"><a href="#适用范围和使用技巧" class="headerlink" title="适用范围和使用技巧"></a>适用范围和使用技巧</h3><p>在FFM原论文中，作者指出，FFM模型对于one-hot后类别特征十分有效，但是如果数据不够稀疏，可能相比其它模型提升没有稀疏的时候那么大，此外，对于数值型的数据效果不是特别的好。</p>
<p>在Github上有FFM的<a target="_blank" rel="noopener" href="https://github.com/guestwalk/libffm">开源实现</a>，要使用FFM模型，特征需要转化为“<strong>field_id:feature_id:value</strong>”格式，相比LibSVM的格式多了field_id，即特征所属的field的编号，feature_id是特征编号，value为特征的值。</p>
<p>此外，美团点评的文章中，提到了训练FFM时的一些注意事项：</p>
<blockquote>
<p>第一，样本归一化。FFM默认是进行样本数据的归一化的 。若不进行归一化，很容易造成数据inf溢出，进而引起梯度计算的nan错误。因此，样本层面的数据是推荐进行归一化的。</p>
<p>第二，特征归一化。CTR/CVR模型采用了多种类型的源特征，包括数值型和categorical类型等。但是，categorical类编码后的特征取值只有0或1，较大的数值型特征会造成样本归一化后categorical类生成特征的值非常小，没有区分性。例如，一条用户-商品记录，用户为“男”性，商品的销量是5000个（假设其它特征的值为零），那么归一化后特征“sex=male”（性别为男）的值略小于0.0002，而“volume”（销量）的值近似为1。特征“sex=male”在这个样本中的作用几乎可以忽略不计，这是相当不合理的。因此，将源数值型特征的值归一化到[0,1]是非常必要的。</p>
<p>第三，省略零值特征。从FFM模型的表达式(3-1)可以看出，零值特征对模型完全没有贡献。包含零值特征的一次项和组合项均为零，对于训练模型参数或者目标值预估是没有作用的。因此，可以省去零值特征，提高FFM模型训练和预测的速度，这也是稀疏样本采用FFM的显著优势。 </p>
</blockquote>
<h2 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h2><p>FM模型可以用神经网络进行表示^[3]^：</p>
<p><img src="../images/machine-learning-fm-ffm-deepfm-deepffm/deep-fm-part.png" alt="deep-fm-part"></p>
<p>模型输入$x = [x_{field_1}, x_{field_2}, \cdots, x_{field_m}]$，这是一个d维的向量，其中$x_{field_i}$即为第i个field的特征表示，如果是类别，则为one-hot编码后的向量，连续值则为它本身。</p>
<p>然后对每个field分别进行embedding，如下图：</p>
<p><img src="../images/machine-learning-fm-ffm-deepfm-deepffm/deep-embedding.png" alt="deep-embedding"></p>
<p>值得注意的是，即使各个field的维度是不一样的，但是它们embedding后<strong>长度均为k</strong>。</p>
<p>接着FM层即为embedding后结果的内积和一次项的和，最后一层sigmoid后再输出结果。</p>
<p>看到这里，可能你感到困惑的就是embedding层，这么表示是为啥？答案是这样表示和fm模型等价！</p>
<p>假设第i个field 向量维度为k，embedding层的参数可以表示为一个k * m的矩阵</p>
<script type="math/tex; mode=display">
V_{field_i}= \begin{bmatrix} 
v_{11} & v_{21} & \cdots & v_{m1} \\ 
v_{12} & v_{22} & \cdots & v_{m2} \\ 
\vdots & \vdots & \ddots & \vdots \\ 
v_{1k} & v_{2k} & \cdots & v_{md} \\ 
\end{bmatrix}</script><p>其中$v_{ab}$可以理解为第a个取值embedding后的结果在隐向量的第b维。</p>
<p>由于进行了one-hot编码，所以对应的$\bf x_{filed_i}$只有一个值为1，其余的都为0,假设第c列为1，则：</p>
<script type="math/tex; mode=display">
V_{field_i}\times {\bf x_{field_i} }=\begin{bmatrix} 
v_{11} & v_{21} & \cdots & v_{m1} \\ 
v_{12} & v_{22} & \cdots & v_{m2} \\ 
\vdots & \vdots & \ddots & \vdots \\ 
v_{1k} & v_{2k} & \cdots & v_{md} \\ 
\end{bmatrix} \times \begin{bmatrix} 0 \\ \vdots \\1\\ \vdots \\ \end{bmatrix}
=  \begin{bmatrix} v_{c1}\\ v_{c2} \\ \vdots \\ v_{ck} \end{bmatrix} x_c= V_c x_c</script><p>若两个field做内积，假设非0的那一列为c和d则：</p>
<script type="math/tex; mode=display">
(V_{field_i} \ x_{field_i})   (V_ {field_j}\ x_{field_j})=( \mathbf{V}_c \cdot \mathbf{V}_d ) x_c x_d</script><p>其实和FM模型是一样的！</p>
<p>DeepFM的模型如下图：</p>
<p><img src="../images/machine-learning-fm-ffm-deepfm-deepffm/deep-fm.png" alt="deep-fm"></p>
<p>左边就是刚才将的FM模型的神经网络表示，而右边的则为deep部分，为全连接的网络，用于挖掘高阶的交叉特征。整个模型共享embedding层，最后的结果就是把FM部分和DNN的部分做sigmoid：</p>
<script type="math/tex; mode=display">
Y = sigmoid(Y_{FM} + Y_{DNN})</script><h2 id="DeepFFM"><a href="#DeepFFM" class="headerlink" title="DeepFFM"></a>DeepFFM</h2><p>类似于FFM对于FM模型来说，划分了field，对于不同的field内积时采用对应的隐向量。同样可以把DeepFM进行进化为DeepFFM，即将每一个field embedding为m个维度为k的隐向量（m为field的个数）</p>
<p>可以参考下图（不过下图没有FFM模型二次项的乘积，实际中也可以加上）</p>
<p><img src="../images/machine-learning-fm-ffm-deepfm-deepffm/deep-ffm.jpg" alt="deep-ffm"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li>Rendle, Steffen. “Factorization machines.” <em>Data Mining (ICDM), 2010 IEEE 10th International Conference on</em>. IEEE, 2010.</li>
<li>Juan, Yuchin, et al. “Field-aware factorization machines for CTR prediction.” <em>Proceedings of the 10th ACM Conference on Recommender Systems</em>. ACM, 2016.</li>
<li>Guo, Huifeng, et al. “Deepfm: A factorization-machine based neural network for CTR prediction.” <em>arXiv preprint arXiv:1703.04247</em> (2017).</li>
<li><a target="_blank" rel="noopener" href="https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html">深入FFM原理与实践</a></li>
<li><a target="_blank" rel="noopener" href="http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf">Factorization Machines</a></li>
<li><a target="_blank" rel="noopener" href="http://research.criteo.com/ctr-prediction-linear-model-field-aware-factorization-machines/">CTR Prediction: From Linear Models to Field-aware Factorization Machines</a></li>
</ol>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          Donate
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://example.com/machine-learning-fm-ffm-deepfm-deepffm/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning-model/" rel="tag">Machine Learning model</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/machine-learning-maximum-entropy-model/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            『我爱机器学习』最大熵原理与最大熵模型
          
        </div>
      </a>
    
    
      <a href="/machine-learning-lightgbm/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">『我爱机器学习』集成学习（四）LightGBM</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "fVcjWMD8aI6F0qEfKdUaHa4f-gzGzoHsz",
    app_key: "b26lBsbwmVyxTSnNrsBrnv3U",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2013-2020
        <i class="ri-heart-fill heart_icon"></i> hrwhisper
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>

 
  <script src="https://cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script src="//cdn1.lncld.net/static/js/2.5.0/av-min.js"></script>
<script type="text/javascript">
var leancloud_app_id  = 'fVcjWMD8aI6F0qEfKdUaHa4f-gzGzoHsz';
var leancloud_app_key = 'b26lBsbwmVyxTSnNrsBrnv3U';

AV.init({
    appId: leancloud_app_id,
    appKey: leancloud_app_key
});

// https://leancloud.cn/docs/leanstorage_guide-js.html#hash1873238850
function showTime(Counter) {
  console.log("show time");
	let query = new AV.Query(Counter);
  query.greaterThanOrEqualTo("time", 0);		
  query.find().then((results) => {
      if (results.length > 0) {
        let data = results;
        $('.leancloud_visitors').each(function() {
          let url = $(this).attr('id').trim();		
          for (let i = 0; i < data.length; i++) {
            let object = data[i];
            let content = object.get('time');
            let _url = object.get('url');
            if(url == _url){
              $(this).text(content);
            }
          }
        });
      }
  });
}

function addCount(Counter) {
  const obj = $(".leancloud_visitors");
	url = obj.attr('id').trim();
  title = obj.attr('data-flag-title').trim();

  const query = new AV.Query('Counter');
  query.equalTo("url", url);

	query.find().then((results) => {
			if (results.length > 0) {
				var counter = results[0];
				counter.increment("time", 1);
				counter.save(null, {fetchWhenSave: true}).then(() => {
          let content = counter.get('time');
          $(document.getElementById(url)).text(content);
        }, (error)=> {
						console.log('Failed to save Visitor num, with error message: ' + error.message);
        });
			} else {
				var newcounter = new Counter();
				newcounter.set("title", title);
				newcounter.set("url", url);
        newcounter.set("time", 1);
        newcounter.save(null, {fetchWhenSave: true}).then(() => {
          var content = newcounter.get('time');
          $(document.getElementById(url)).text(content);
        }, (error)=> {
          console.log('Failed to create' + error.message);
        });
			}
	});
}

$(function() {
  var Counter = AV.Object.extend("Counter");
	if ($('.leancloud_visitors').length == 1) {
		addCount(Counter);
	} else {
	  showTime(Counter);
  }
}); 
</script>


      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/site/logo.jpg" alt="细语呢喃"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/blog-building">博客建设</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friend-link">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/leetcode-algorithm-solution">leetcode题解</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/messageboard">留言板</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about-me">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/donate/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/donate/wechat_pay.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3',
    hasInnerContainers: true,
    scrollSmooth: false,
	  scrollSmoothDuration: 420,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto',
	collapseDepth: 2,
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>