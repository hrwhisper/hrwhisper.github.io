<!DOCTYPE html>


<html lang="zh-CN">


<head>
  <meta charset="utf-8" />
   
  <meta name="keywords" content="c,c++,java,python,leetcode,algorithm,reading,life,moods,machine-learning,data-mining,deep-learning,AI" />
   
  <meta name="description" content="一个分享机器学习、算法与数据结构，个人学习心得、读书笔记、生活的博客。" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    【Paper Weekly】 Learning Lane Graph Representations for Motion Forecasting |  一个分享机器学习、算法与数据结构，个人学习心得、读书笔记、生活的博客。
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/images/site/avatar.jpg" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

</head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-learning-lane-graph-Representations-for-motion-forecasting"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  【Paper Weekly】 Learning Lane Graph Representations for Motion Forecasting
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/uber-learning-lane-graph-Representations-for-motion-forecasting/" class="article-date">
  <time datetime="2020-11-21T02:53:07.000Z" itemprop="datePublished">2020-11-21</time>
</a> 
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a> / <a class="article-category-link" href="/categories/study/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/">自动驾驶</a>
  </div>
 
       
        
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">2.6k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">10 分钟</span>
        </span>
    </span>
</div>

      
       
        <div class="word_count">
    <span class="post-meta-item-icon">
        <i class="ri-eye-fill"></i> 
        阅读数:<span id="/uber-learning-lane-graph-Representations-for-motion-forecasting/" data-flag-title="【Paper Weekly】 Learning Lane Graph Representations for Motion Forecasting" class="leancloud_visitors">0</span>次
    </span>
</div>
      
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="overview">Overview</h2>
<p>这是一篇来自Uber行为预测的文章。</p>
<p>和VectorNet类似，没有用语义地图来对网络进行encode，而是提出了<code>LaneGCN</code>，它使用多个邻接矩阵扩展图的卷积操作，并沿车道进行尺度扩张。为了能够获取复杂车辆和地图的交互，提出了融合网络<code>fusion network</code>进行建模，它包括actor-to-lane, lane-to-lane, lane-to-actor 和 actor-to-actor。</p>
<p>这篇paper提出的方法在Argoverse数据集上取得了SOTA的效果。</p>
<a id="more"></a>
<h3 id="过往方法的缺点">过往方法的缺点</h3>
<p>同样也是在说语义地图的方法的缺点</p>
<ol type="1">
<li>rasterization 的过程不可避免的会导致信息的丢失</li>
<li>使用二维卷积捕捉地图图结构复杂的拓扑结构，效率可能会很低</li>
</ol>
<h3 id="主要贡献">主要贡献</h3>
<ol type="1">
<li>提出laneGCN，可以有效捕捉复杂的车道拓扑结构和长时依赖</li>
<li>将actor和车道表征为图中的节点，使用1D CNN和LaneGCN，分别提取actor和车道的节点特征，利用A2L, L2L, L2A, A2A来捕捉交互特征</li>
<li>在Argoverse数据集上取得SOTA的效果</li>
</ol>
<h3 id="和vectornet的对比">和VectorNet的对比</h3>
<blockquote>
<p>First, VectorNet uses vanilla graph networks with undirected full connections, while we build a sparsely connected lane graph following the map topology and propose task specific multi-type and dilated graph operators.</p>
<p>Second, VectorNet uses polyline-level nodes for interaction, while our LaneGCN uses polyline segments as map nodes to capture higher resolution. Note that in our approach nodes in different polylines can interact with each other through dilated connections.</p>
</blockquote>
<ul>
<li>VectorNet使用无向全连接的普通图网络（Vanilla GCN），本文根据地图的拓扑构建了稀疏的图，并提出空洞卷积来扩展图的操作</li>
<li>VectorNet使用折线级的节点进行交互，而我们的LaneGCN使用折线段作为地图节点以获取更高的分辨率。注意，在我们的方法中，不同折线中的节点可以扩展连接的相互作用。</li>
</ul>
<h2 id="网络结构">网络结构</h2>
<p><img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/overall-architecture.png" alt="overall-architecture" /> 主要是几个部分：</p>
<ul>
<li>ActorNet从观察到的过去轨迹中提取行动者的特征</li>
<li>HDMap中构造车道图像并使用LaneGCN提取地图特征。</li>
<li>然后使用FusionNet融合模型模拟actor和车道图之间的交互，并预测未来的轨迹</li>
</ul>
<h3 id="actornet">ActorNet</h3>
<figure>
<img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/actor-net.png" alt="actor-net" /><figcaption aria-hidden="true">actor-net</figcaption>
</figure>
<p>对于actor过去的轨迹 <span class="math inline">\(\{\Delta P_{-(T-1)}, ..., \Delta P_{-1}, \Delta P_{0} \}\)</span>, （<span class="math inline">\(\Delta P_t)\)</span>为2D的坐标），可以构造出模型的输入：</p>
<ul>
<li>模型输入： <span class="math inline">\((x, y, mask) * T\)</span>， mask代表不足T的长度则补0</li>
<li>模型：用3组多1D的CNN，每组包含2个残差块 + FPN网络</li>
<li>模型输出： <span class="math inline">\((128, 1)\)</span></li>
</ul>
<p>这里简单的介绍下FPN网络，结构如下图</p>
<figure>
<img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/fpn-net.png" alt="fpn-net" /><figcaption aria-hidden="true">fpn-net</figcaption>
</figure>
<p>FPN网络提出来是用在目标检测的任务上。</p>
<ol type="1">
<li>图a代表将图片进行缩放，对每个缩放的图（也就是不同的尺度）都进行预测，但是这个耗时毕竟大</li>
<li>图b是经典的做法，通过cnn提取特征，然后最后一层得到的feature map用来检测物体，但是小物体在小的feature map上体现不是很明显，效果不好。如Faster R-CNN</li>
<li>图c从图b进行改进，是一种多尺度的方法：大的物体用小的特征图，小的物体用大的特征图，代表是SSD</li>
<li>图d更进一步，顶层特征通过上采样和低层特征做融合，能得到更好的特征表达</li>
</ol>
<h3 id="mapnet">MapNet</h3>
<figure>
<img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/map-net.png" alt="map-net" /><figcaption aria-hidden="true">map-net</figcaption>
</figure>
<p>一些定义：</p>
<ul>
<li>将Lane node定义为车道中心线任意两个相邻点的连线，它的坐标就是两点之间的平均坐标。</li>
<li>对于Lane node A, 它的前继和后继就是可以直接从A到达的相邻节点；比如图3右图的橙色和蓝色节点</li>
<li>而它的左右邻居定义为最近的节点（l2距离），比如图3右图的紫色和绿色</li>
</ul>
<p>因此可以定义4个N * N的矩阵<span class="math inline">\(\{A_i\}_{i \in\{pre,suc,left,right\}}\)</span>， <span class="math inline">\(A_{i,j,k} = 1\)</span> 表示节点k对于节点j是第i种type的关系。</p>
<h4 id="传统gcn">传统GCN</h4>
<p>不熟悉GCN可以参考： <a target="_blank" rel="noopener" href="http://tkipf.github.io/graph-convolutional-networks/">graph-convolutional-networks</a></p>
<p>广泛使用的Graph convolution operator定义为： <span class="math display">\[
Y = LXW
\]</span> X为节点的特征，W是权重的矩阵，L为归一化的拉普拉斯矩阵： <span class="math display">\[
L = D^{-1/2} (I + A) D^{-1/2}
\]</span> 其中D为度矩阵，A为邻接矩阵，I为单位阵。</p>
<p>但是这个普通的卷积方法在我们要处理的case中是比较没效率的：</p>
<blockquote>
<p>First, it is not clear what kind of node feature will preserve the information in the lane graphs.</p>
<p>Second, a single graph Laplacian can not capture the connection type, i.e., losing the directional information carried by the connection type.</p>
<p>Third, it is not straightforward to handle long range dependencies, e.g., akin dilated convolution, within this form of graph convolution.</p>
</blockquote>
<p>基于上面的几个缺点，提出了LaneConv的操作</p>
<h4 id="node-feature">Node Feature:</h4>
<p>考虑节点的shape（大小和方向）还有坐标： <span class="math display">\[
x_i = \text{MLP}_{shape}(v_i^{end} - v_i^{start}) + \text{MLP}_{loc}(v_i) 
\]</span></p>
<p>MLP就是多层感知机， <span class="math inline">\(v_i^{end}\)</span>和 <span class="math inline">\(v_i^{start}\)</span>是节点i的start和end的point的坐标，<span class="math inline">\(v_i\)</span>就是第i个节点的坐标； <span class="math inline">\(x_i\)</span>是节点特征矩阵<span class="math inline">\(X\)</span>的第i行，代表第i个lane节点的特征。</p>
<h4 id="laneconv基本操作">LaneConv基本操作</h4>
<p><span class="math display">\[
Y = XW_0 + \sum_{i\in \{pre,suc,left,right\}} A_iXW_i
\]</span></p>
<p><span class="math inline">\(A_i\)</span>和<span class="math inline">\(W_i\)</span>是邻接矩阵和权重矩阵，i代表对应的关系。</p>
<p>这里有个问题，用了4个矩阵<span class="math inline">\(A\)</span>，相比直接一个A表示连接关系的区别？</p>
<p>个人认为是 对不同的连接关系可以用不同的权重来表达，提取的信息会更加的丰富</p>
<h4 id="dilated-laneconv-空洞lane卷积">Dilated LaneConv: 空洞lane卷积</h4>
<p>学习CNN种空洞卷积提升感受野的操作，提出了k-dilation LaneConv： <span class="math display">\[
Y = XW_0 + A^k_{pre}XW_{pre,k} + A^k_{suc}XW_{suc, k}
\]</span> <span class="math inline">\(A^k_{pre}\)</span>是矩阵<span class="math inline">\(A_{pre}\)</span>的k次方，这使得我们可以通过k步来传递信息。</p>
<p>注意：Dilated LaneConv只用在前继和后继上。</p>
<h4 id="laneconv的最终形式">LaneConv的最终形式</h4>
<p><span class="math display">\[
Y = XW_0 + \sum_{i\in \{left,right\}} A_iXW_i + \sum_{c=1}^C \left( A^{k_c}_{pre}XW_{pre,k_c} + A^{k_c}_{suc}XW_{suc, k_c} \right)
\]</span></p>
<p>实践中，采用了<code>LaneConv(1, 2, 4, 8, 16, 32)</code>，见图4</p>
<figure>
<img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/laneGCN-architecture.png" alt="laneGCN-architecture" /><figcaption aria-hidden="true">laneGCN-architecture</figcaption>
</figure>
<h3 id="fusionnet">FusionNet</h3>
<p>先前的工作更多的是处理actor之间的交互，actor和地图的交互相关研究较少。</p>
<p>融合模块由四个网络子模块组成，用于处理actor和车道节点之间所有的信息流，actors to lanes (A2L), lanes to lanes (L2L), lanes to actors (L2A) and actors to actors (A2A)</p>
<ul>
<li>A2L引入了实时交通信息, 如堵塞或使用的车道</li>
<li>L2L通过传播交通信息来更新lane节点的特征</li>
<li>L2A将更新地图特征并与实时交通信息进行融合，反馈给actor</li>
<li>A2A处理actor之间的交互并输出actor的特征，然后用于轨迹的预测</li>
</ul>
<p>L2L采用了之前说的LaneGCN方法，对于其他的A2L,L2A,A2A采用了spatial attention layer，它们三个建模方式是一样的，以A2L举例来说：给定actor节点i，通过context的lane node j来聚合特征：</p>
<p><span class="math display">\[
y_i = x_i W_0 + \sum_j \phi\left(concat\left(x_i, \Delta_{i,j}, x_j\right)W_1 \right)W_2
\]</span></p>
<p>类似的<span class="math inline">\(x_i\)</span>是第i个节点的特征，W为权重矩阵，<span class="math inline">\(\phi\)</span>代表<code>layer normalization + RELU</code>，<span class="math inline">\(\Delta_{ij} = \text{MLP}(v_j - v_i)\)</span> context的节点定义为l2距离小于一定阈值的节点， A2L, L2A 和A2A 分别设置为7，6，和100米。</p>
<hr />
<p>PS: 感觉这里原文表达有些问题，如A2L应该是更新lane的节点特征，上面的式子感觉actor i也会更新。 另外，这里的attention和论文引用的transform的self-attention感觉diff也比较大，似乎attention只是体现在W矩阵中</p>
<p>最后完整的网络如下：</p>
<figure>
<img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/all-network.png" alt="all-network" /><figcaption aria-hidden="true">all-network</figcaption>
</figure>
<h3 id="prediction-header">Prediction Header</h3>
<p>使用两个分支，一个分支是回归模型，用来预测k个轨迹，一个分支是分类模型，用来对每个模态进行打分</p>
<h3 id="learning">Learning</h3>
<p><span class="math display">\[
L = L_{cls} + \alpha L_{reg}
\]</span> 分类采用了max-margin的loss，其中，M为actor的总数，K为轨迹生成的数量，<span class="math inline">\(\hat{k}\)</span>为k条轨迹中具有最小FDE的那条轨迹，以此为label，c为分类模型的置信度输出。 <span class="math display">\[
L_{cls} = \frac{1}{M(K-1)} \sum_{m=1}^M \sum_{k \ne \hat{k}} \max\left(0, c_{m,k} + \epsilon - c_{m,\hat{k}} \right)
\]</span></p>
<p>回归用smooth-l1 loss （每个时刻都统计损失） <span class="math display">\[
L_{reg} = \frac{1}{MT} \sum_{m=1}^{M} \sum_{t=1}^T reg(\boldsymbol{p}_{m,t}^{\hat{k}} - \boldsymbol{p}_{m,t}^{*})
\]</span> 其中，<span class="math inline">\({p}_{t}^{*}\)</span>是ground truth在t时刻的BEV的坐标， <span class="math inline">\(reg(\boldsymbol{x}) = \sum_i d(x_i)\)</span>，<span class="math inline">\(d(x_i)\)</span>就是smooth l1 loss: <span class="math display">\[
d(x_i)=\left\{
\begin{aligned}
 0.5x_i^2 &amp;&amp; if \left\lVert x_i \right\rVert &lt; 1\\
\left\lVert x_i\right\rVert - 0.5 &amp;&amp; otherwise,
\end{aligned}
\right.
\]</span> <span class="math inline">\(\left\lVert x_i\right\rVert\)</span>是 <span class="math inline">\(x_i\)</span>的L1 norm</p>
<h2 id="实验">实验</h2>
<h3 id="dataset">Dataset</h3>
<p>Argoverse: 5s轨迹，前2s作为历史信息输入， 后3s预测</p>
<p>训练、验证、测试集数量分别是205942, 39472和78143</p>
<h3 id="implementation-details">Implementation Details</h3>
<p>对所有actor和lane距离主车 &lt; 100m的作为输入，以T=0时刻主车为中心，主车t=-1和t=0作为x轴的正半轴。</p>
<p>使用了4个TITAN-X GPU训练， batchsize设为128， learning rate初始设置为<span class="math inline">\(1\times10^{-3}\)</span>, 32个epoch后降为<span class="math inline">\(1\times10^{-4}\)</span>，训练总共36epoch。</p>
<h3 id="实验分析">实验分析</h3>
<h4 id="和其他模型对比">和其他模型对比</h4>
<figure>
<img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/argoverse-benchmark.png" alt="argoverse-benchmark" /><figcaption aria-hidden="true">argoverse-benchmark</figcaption>
</figure>
<p>SOTA的效果</p>
<h4 id="importance-of-each-module">Importance of each module</h4>
<p>实验2表明 1. 所有的网络都有一定的性能提升，证明了LaneGCN和网络结构的有效性 2. A2L and L2L 比只用 L2A 效果好很多，说明 actor向map传递了很多有效的信息</p>
<figure>
<img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/ablation-study-of-modules.png" alt="ablation-study-of-modules" /><figcaption aria-hidden="true">ablation-study-of-modules</figcaption>
</figure>
<h3 id="lane-graph-operators">Lane Graph Operators</h3>
<p>表3说明</p>
<ol type="1">
<li>加入残差块能有效的提高性能</li>
<li>multi-type(前继后继、左右邻居) 和空洞卷积也能提高性能</li>
</ol>
<figure>
<img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/ablation-study-of-lane-graph-operators.png" alt="ablation-study-of-lane-graph-operators" /><figcaption aria-hidden="true">ablation-study-of-lane-graph-operators</figcaption>
</figure>
<h3 id="qualitative-results">Qualitative Results</h3>
<p>给了4个hard case，如下</p>
<figure>
<img src="../images/2020-11-21-learning-lane-graph-Representations-for-motion-forecasting/hard-cases.png" alt="hard-cases" /><figcaption aria-hidden="true">hard-cases</figcaption>
</figure>
<ol type="1">
<li>第1行其他的模型都丢失了右转的模态，而本文的模型可以成功预测</li>
<li>第2行是在无保护左转的路口, 车辆已经在路口中停留超过2s,缺少历史的信息, 但是本文的模型还是能成功的预测</li>
<li>第3行说本文提出的方法比其他的三个都好一些,(轨迹短一些, 虽然也没有很好, 感觉是矮子里拔将军)</li>
<li>第4行猛加速都没预测对</li>
</ol>
<h2 id="小结">小结</h2>
<p>Uber提出的这篇论文感觉laneGcn还是值得借鉴的。</p>
<p>但是感觉后面fusion net部分讲得不是特别清楚，如attention感觉不太对，而且估计耗时也毕竟大。</p>
<h2 id="参考文献">参考文献</h2>
<ul>
<li>Liang M, Yang B, Hu R, et al. Learning lane graph representations for motion forecasting[C]//European Conference on Computer Vision. Springer, Cham, 2020: 541-556.</li>
<li>Lin T Y, Dollár P, Girshick R, et al. Feature pyramid networks for object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 2117-2125.</li>
</ul>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          打赏
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://www.hrwhisper.me/uber-learning-lane-graph-Representations-for-motion-forecasting/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/paper/" rel="tag">paper</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/prediction/" rel="tag">prediction</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/self-driving-car/" rel="tag">self-driving car</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/waymo-tnt-target-driveN-trajectory-prediction-paper/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            【Paper Weekly】TNT: Target-driveN Trajectory Prediction
          
        </div>
      </a>
    
    
      <a href="/waymo-vectornet/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">【Paper Weekly】VectorNet: Encoding HD Maps and Agent Dynamics From Vectorized Representation</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "fVcjWMD8aI6F0qEfKdUaHa4f-gzGzoHsz",
    app_key: "b26lBsbwmVyxTSnNrsBrnv3U",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2013-2021
        <i class="ri-heart-fill heart_icon"></i> hrwhisper
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        由 <a href="https://hexo.io" target="_blank">Hexo</a> 强力驱动
        <span class="division">|</span>
        主题 - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>

 
  <script src="https://cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script src="//cdn1.lncld.net/static/js/2.5.0/av-min.js"></script>
<script type="text/javascript">
var leancloud_app_id  = 'fVcjWMD8aI6F0qEfKdUaHa4f-gzGzoHsz';
var leancloud_app_key = 'b26lBsbwmVyxTSnNrsBrnv3U';

AV.init({
    appId: leancloud_app_id,
    appKey: leancloud_app_key
});

// https://leancloud.cn/docs/leanstorage_guide-js.html#hash1873238850
function showTime(Counter) {
  console.log("show time");
  const query = new AV.Query(Counter);
  const obj = $(".leancloud_visitors");

  let urls = [];
  obj.each(function() {
    urls.push($(this).attr('id').trim());
  });
  query.containedIn('url', urls);
  query.find().then((results) => {
      if (results.length > 0) {
        let data = results;
        obj.each(function() {
          let url = $(this).attr('id').trim();		
          for (let i = 0; i < data.length; i++) {
            let object = data[i];
            let content = object.get('time');
            let _url = object.get('url');
            if(url == _url){
              $(this).text(content);
            }
          }
        });
      }
  }).catch((error) => {
    console.error(error);
  });
}

function addCount(Counter) {
  const obj = $(".leancloud_visitors");
	url = obj.attr('id').trim();
  title = obj.attr('data-flag-title').trim();

  const query = new AV.Query(Counter);
  query.equalTo("url", url);

	query.find().then((results) => {
			if (results.length > 0) {
				var counter = results[0];
        counter.increment("time", 1);
        counter.set("title", title);
				counter.save(null, {fetchWhenSave: true}).then(() => {
          let content = counter.get('time');
          $(document.getElementById(url)).text(content);
        }, (error)=> {
						console.log('Failed to save Visitor num, with error message: ' + error.message);
        });
			} else {
				var newcounter = new Counter();
				newcounter.set("title", title);
				newcounter.set("url", url);
        newcounter.set("time", 1);
        newcounter.save(null, {fetchWhenSave: true}).then(() => {
          var content = newcounter.get('time');
          $(document.getElementById(url)).text(content);
        }, (error)=> {
          console.log('Failed to create' + error.message);
        });
			}
	}).catch((error) => {
    console.error(error);
  });
}

$(function() {
  var Counter = AV.Object.extend("Counter");
	if ($('.leancloud_visitors').length == 1) {
		addCount(Counter);
	} else {
	  showTime(Counter);
  }
}); 
</script>


      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/site/avatar.jpg" alt="细语呢喃"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/blog-building">博客建设</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friend-link">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/leetcode-algorithm-solution">leetcode题解</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about-me">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/donate/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/donate/wechat_pay.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3',
    hasInnerContainers: true,
    scrollSmooth: false,
	  scrollSmoothDuration: 420,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto',
	collapseDepth: 2,
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->

<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>